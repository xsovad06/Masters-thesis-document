\kap[chapter:theoretical-foundation]{Theoretical foundations}
This chapter provides an overview of the theoretical foundations of the proposed automated \NN\-s learning approach for human skeleton detection. It introduces the key concepts of \NN\-s, convolutional neural network  (\CNN\), region-based convolutional neural network  (\RCNN\), and transformation models of \NN\-s. Additionally, it explores existing \NN\-s for human pose estimation, including {\em PoseNet}, {\em MoveNet}, and {\em MMPose}.

% ------- Section ------- %
\pkap[section:neural-network]{Neural Network}
\NN\-s, inspired by the structure and function of the {\em human brain}, are computational models comprising {\em interconnected} layers of artificial {\em neurons} responsible for processing and transforming information. Demonstrating remarkable capabilities, \NN\-s have proven effective in diverse tasks, including image recognition, natural language processing, and machine translation. A~schematic representation of a simple \NN\ is presented in \in{Figure}[nn-schema], illustrating individual layers of neurons interconnected with their neighbors. The initial layer is commonly referred to as the {\em input layer}, followed by {\em hidden layers}, and concluding with the {\em output layer}. In practical usage, data, such as an image in the form of a vector where values represent individual pixels, is input into the initial layer for analysis. The \NN\ processes this information, ultimately yielding a result in the form of a single value or vector, dependent on the nature of the problemâ€”be it a classification or regression task. Across various fields, \NN\-s have consistently demonstrated their robustness, excelling in tasks such as classification, prediction, filtering, optimization, pattern recognition, and function approximation (\scc Simoneau et al., 1998).
\obrazek{nn-schema}{Example neural network schema. Source: (\\scc Nielsen, 2015)}{figures/neural-network-schema.png}{width=\makeupwidth}

\ppkap[subsection:nn-works]{How Neural Network Works}

A~\NN\, inspired by the human brain, is a computational system organized into layers of artificial neurons (\scc Nielsen, 2015). Each connection between neurons has a {\em weight}, representing the strength of influence (\scc Goodfellow et al., 2016). The network learns by adjusting these weights during training, where it processes input data through layers, utilizes {\em activation functions} to determine neuron \uv{firing}, and iteratively adjusts weights based on the difference between predicted and actual outcomes (\scc Nielsen, 2015; \scc Goodfellow et al., 2016; \scc Mazur, 2015). The forward pass involves making predictions, while the backward pass compares predictions to actual results, adjusting weights to minimize {\em errors} (\scc Mazur, 2015). This learning process enables the neural network to recognize patterns and make accurate decisions in tasks like {\em image recognition} or {\em language processing} (\scc Goodfellow et al., 2016).

% ------- Section ------- %
\pkap[section:cnn]{Convolutional Neural Network}
\CNN\-s are a type of \NN\ architecture that excels at processing and analyzing visual data, such as images and videos. They are particularly well-suited for skeleton detection due to their ability to {\em extract} local features from the input data. \CNN\-s typically consist of a series of {\em convolutional layers}, each of which applies a {\em filter} or {\em kernel} to the input data to extract {\em features}. The filters are learned during the training process, allowing the \CNN\ to learn the patterns and relationships that are important for skeleton detection (\scc Singh, 2019). For better understanding of the \CNN\ architecture see example \in{Figure}[cnn-schema].

\CNN\-s have several advantages for skeleton detection (\scc Huang, 2022):

\startitemize[1]
    \item {\bf Translation Invariance:} \CNN\-s are invariant to small translations in the input data. This is important for skeleton detection, as the human body can be in {\em different positions} in an image or video.
    \item {\bf Feature Learning:} \CNN\-s can learn {\em complex features} from the input data, which is essential for accurate skeleton detection.
    \item {\bf Parameter Sharing:} \CNN\-s share {\em weights} across different positions in the input data. This reduces the number of parameters in the network, making it more efficient and easier to train.
\stopitemize

\CNN\-s have become the dominant architecture for skeleton detection, and they have significantly improved the accuracy of this task (\scc Singh, 2019\; \scc Huang, 2022).
\obrazek{cnn-schema}{A simple classification architecture by CNN. Source: (\\scc Koushik, 2023)}{figures/cnn-schema.png}{width=\makeupwidth}

\ppkap[subsection:cnn-works]{How Convolutional Layers Work}

Each convolutional layer in a CNN takes an input image and applies a filter to it to extract features. The filter is a small matrix of weights that slides across the input image, producing a feature map at each position. The feature map is a representation of the input image that highlights the patterns that are relevant to the task at hand (\scc Agarwal et al., 2019).

For example, in the case of human skeleton detection, a filter might be used to extract features that are indicative of human joints, such as the elbows, knees, and wrists. The feature map produced by this filter would highlight the locations of these joints in the input image.

\ppkap[subsection:cnn-pooling-layers]{Pooling Layers}

After the convolutional layers extract features, pooling layers are often used to reduce the dimensionality of the feature maps. This helps to reduce the computational cost of the network and also helps to make the network more invariant to small changes in the input data.

Pooling layers work by dividing the feature map into smaller regions and then taking the maximum or average value of each region. This produces a smaller feature map that still contains the most important features from the original image (\scc Agarwal et al., 2019).

\ppkap[subsection:cnn-fully-connected-layers]{Fully Connected Layers}

Once the feature maps have been extracted and pooled, they are passed through a series of fully connected layers. These layers are similar to the artificial neurons that are found in traditional neural networks. They take an input vector and produce an output vector.

In the case of human skeleton detection, the fully connected layers are used to classify the detected features as either human joints or background. The output vector from the final fully connected layer is a probability distribution over the possible classes (\scc Agarwal et al., 2019).

\ppkap[subsection:cnn-training]{Training the CNN}

The CNN is trained using a process called {\em supervised learning} (\scc Liu, 2012). This involves providing the network with a dataset of labeled images, where each image is labeled with the positions of the human joints. The network then learns to associate the features extracted from the images with the corresponding labels.

The training process involves adjusting the weights of the filters and connections in the network. This is done using an algorithm called backpropagation (\scc Mazur, 2015), which iteratively updates the weights to minimize the error between the network's predictions and the ground truth labels (\scc Agarwal et al., 2019).

\ppkap[subsection:cnn-example-usage]{Example of CNN Usage}

To illustrate how a CNN is used for human skeleton detection, consider a scenario where a CNN is tasked with detecting human skeletons in a video stream. The CNN would first extract features from each frame of the video using its convolutional layers. Then, it would use these features to predict the positions of the human joints in the frame. This predictions can be used for various analysis of the human body movements in the video.

\ppkap[subsection:cnn-limitations]{Limitations of Current Methods}

While CNNs have achieved significant success in human skeleton detection, there are still some limitations to these methods. One limitation is that CNNs can be {\em computationally expensive}, especially when dealing with {\em high-resolution} images or videos. Additionally, CNNs can be sensitive to {\em noise} and {\em occlusions}, which can make it difficult to accurately detect skeletons in real-world scenarios.

Researchers are continuing to develop new methods to improve the accuracy and efficiency of CNNs for human skeleton detection. These methods include using deeper networks, exploring new architectures, and developing more efficient training algorithms (\scc Agarwal et al., 2019).

% ------- Section ------- %
\pkap[section:rcnn]{Region-based Convolutional Neural Network}
\RCNN\-s are a class of deep \CNN\-s that have been widely used for object detection and localization. They are typically characterized by a {\em two-stage} pipeline that involves {\em region proposal} and {\em region classification} (\scc Ren et al., 2015). In the \in{Figure}[rcnn-stages] is displayed possible detection scenario of the \RCNN\.
\obrazek{rcnn-stages}{RCNN stages. Source: (\\scc Girshick, 2016)}{figures/rcnn-stages.png}{width=\makeupwidth}

\startitemize[1]
    \item {\bf Region Proposal:} The first stage of an \RCNN\ involves generating a set of region proposals, which are candidate {\em bounding boxes} for objects in the input image. These proposals are typically generated using a {\em selective search algorithm} (\scc He et al., 2015) that identifies regions that are likely to contain objects based on their visual saliency and spatial context (\scc Girshick et al., 2016).
    \item {\bf Feature Extraction and Classification:} The second stage of an \RCNN\ involves classifying each region proposal as either {\em containing} the object or {\em not} (\scc Ren et al., 2015). This is accomplished by using a \CNN\ to extract feature vectors from each proposal and then applying a classifier to determine whether the features are indicative of the object (\scc Girshick et al., 2016).
\stopitemize

The original \RCNN\ architecture has been criticized for its computational {\em inefficiency}, as it involves two separate stages of processing (\scc Ren et al., 2015). To address this issue, researchers developed {\em Faster R-CNN}, which integrates the region proposal and region classification stages into a {\em single network} (\scc Ren et al., 2015). This significantly reduces the computational cost and improves the overall performance of the system (\scc He et al., 2015).
% ------- Section ------- %
% \pkap[section:transformation-models]{Transformation Models of \NN\-s}
% Transformation models aim to improve the performance and efficiency of \NN\-s by transforming the input or output data. These models can be used to reduce the dimensionality of the data, improve the interpretability of the model, or adapt the model to specific tasks.

% ------- Section ------- %
\pkap[section:existing-nns]{Existing \NN\-s for Human Pose Estimation}
Several \NN\ architectures have been developed for skeleton detection. This thesis explores three notable examples, each with a dedicated section in this chapter:

\startitemize[n]
    \item {\bf PoseNet} (Mediapipe): A~lightweight and efficient \NN\ for human pose estimation. It uses a single-stage architecture and can run on mobile devices.
    \item {\bf MoveNet} (TensorFlow): A~multimodal \NN\ that combines pose estimation, hand tracking, and object tracking. It offers a variety of models with different tradeoffs between accuracy and speed.
    \item {\bf MMPose} (Open-MMLab): A~modular and extensible library for pose estimation. It provides a wide range of models and training tools.
\stopitemize

% ------- Section ------- %
\pkap[section:posenet]{PoseNet}
{\em Pose_landmark} (\PoseNet\) is a single person detection model from the MediaPipe family that is used to detect keypoints or pose landmarks on human body in images and videos. It is a \CNN\--based model that uses a {\em two-stage} pipeline to first detect person {\em bounding box} and then refine the detection by {\em estimating} the positions of {\bf 33} {\em keypoints} on detected person (\scc Posenet, 2024). The ouput structure of the {\em PoseNet} model can be found in \in{Figure}[posenet-skeleton].

The first stage of the pipeline, the person detection stage, uses a Single Shot MultiBox Detector (\SSD\) to generate bounding box around person in the input image. The SSD is a lightweight and efficient \CNN\ architecture that is well-suited for real-time applications (\scc PoseNet, 2024).

The second stage of the pipeline, the pose estimation stage, uses a \CNN\ to refine the person detections by estimating the positions of 33 keypoints on detected person. The keypoints are typically located on the joints of the human body, such as the elbows, knees, and wrists (\scc PoseNet, 2024).

The \PoseNet\ model is trained on a large COCO dataset (\scc Tsung-Yi, 2015) with images and videos of people performing a variety of actions. This training data helps the model to learn to identify the keypoints on human bodies in a variety of poses and orientations. In the Table below can be found some of the key features of the \PoseNet\ model.

\TABULKA[][tab:posenet-features]{PoseNet model features}
    \setupTABLE[r][1][style=bold]
    \setupTABLE[c][each][offset=3dd]
    \setupTABLE[frame=off]
    \setupTABLE[r][1][topframe=on,bottomframe=on]
    \setupTABLE[c][each][leftframe=on]
    \setupTABLE[c][1][leftframe=off]
    \bTR
        \bTD Feature\eTD\bTD    Description\eTD\eTR
    \bTR
        \bTD Input\eTD\bTD	    RGB image or video frame\eTD\eTR
    \bTR
            \bTD Output\eTD\bTD	    Pose landmarks for a person detected in the input\eTD\eTR
    \bTR
        \bTD Landmarks\eTD\bTD	33 keypoints\eTD\eTR
    \bTR
        \bTD Accuracy\eTD\bTD	Up to 83\% accuracy on the COCO dataset\eTD\eTR
    \bTR
        \bTD Speed\eTD\bTD	    10 - 20 FPS\eTD\eTR

\obrazek{posenet-skeleton}{PoseNet skeleton structure with IDs to each keypoint. The skeleton representation plays a crucial role in introducing the unified format as described in \\in{section}[section:unified-format] on \\at{page}[section:unified-format]. Source: (\\scc PoseNet, 2024).}{figures/posenet-detection-structure.png}{width=34cc}

% ------- Section ------- %
\pkap[section:movenet]{MoveNet}
MoveNet is a family of {\em lightweight} and {\em efficient} pose estimation models developed by Google AI for {\em real-time} human pose estimation. In this thesis the {\em lightning} version of the model was used. It is designed for mobile and embedded devices. MoveNet employs a {\em two-stage} pipeline to achieve real-time performance while maintaining high {\em accuracy} (\scc MoveNet, 2024). The ouput structure of the {\em MoveNet} model can be found in \in{Figure}[movenet-skeleton].

The first stage is responsible for detecting and predicting the rough location of human body in an image or video frame. It utilizes a \SSD\ architecture to generate {\em bounding box} around potential person (\scc MoveNet, 2024).

The second stage refines the pose estimation results by utilizing a single-person pose estimation model. This model takes the one bounding box predicted in the first stage and refines it to pinpoint the locations of {\bf 17} {\em keypoints} on the one detected person. The keypoints correspond to prominent joints on the human body, such as the elbows, knees, hips, and shoulders (\scc Khanh, 2021).

The single-person pose estimation model utilizes a heatmap-based approach, where each keypoint is associated with a heatmap that indicates the probability of the keypoint being present at a particular location in the image. The model then refines the bounding box by iteratively adjusting it to maximize the overall likelihood of the keypoints being within the bounding box (\scc Khanh, 2021).

MoveNet focus on detecting the pose of the person who is closest to the image center and ignore the other people who are in the image frame (i.e. background people rejection) (\scc Google, 2021).

The pose refinement process is repeated multiple times to improve the accuracy of the pose estimation results. The final output of is a set of 17 keypoints for the one detected person. These keypoints provide a detailed representation of the person's pose, including the positions of their joints, limbs, and other landmarks (\scc Khanh, 2021).

\TABULKA[][tab:movenet-features]{MoveNet model features}
    \setupTABLE[r][1][style=bold]
    \setupTABLE[c][each][offset=3dd]
    \setupTABLE[frame=off]
    \setupTABLE[r][1][topframe=on,bottomframe=on]
    \setupTABLE[c][each][leftframe=on]
    \setupTABLE[c][1][leftframe=off]
    \bTR
        \bTD Feature\eTD\bTD    Description\eTD\eTR
    \bTR
        \bTD Input\eTD\bTD	    RGB image or video frame\eTD\eTR
    \bTR
        \bTD Output\eTD\bTD	    Pose landmarks for a person detected in the input\eTD\eTR
    \bTR
        \bTD Landmarks\eTD\bTD	17 keypoints\eTD\eTR
    \bTR
        \bTD Accuracy\eTD\bTD   Up to 88\% on the COCO dataset\eTD\eTR
    \bTR
        \bTD Speed\eTD\bTD	    Up to 30 FPS\eTD\eTR

\obrazek{movenet-skeleton}{MoveNet skeleton structure with IDs to each keypoint. This model simplifies the pose detection process compared to the PoseNet described in \\in{section}[posenet-skeleton] on \\at{page}[posenet-skeleton], which contributes to its superior performance. As a result, the MoveNet detection results do not contribute significantly to the accuracy of the unified format described in \\in{section}[section:unified-format] on \\at{page}[section:unified-format].}{figures/movenet-detection-structure.png}{width=34cc}

% ------- Section ------- %
\pkap[section:mmpose]{MMPose}
This section describes the model and architecture used for multiple humans pose estimation in the {\em MMPose} library (\scc MMPose, 2020). The model is based on a \CNN\ that is trained on a large dataset of images and their corresponding ground truth human poses. The network is able to predict the positions of {\bf 133} {\em keypoints} on the human body, including the head, shoulders, elbows, wrists, hips, knees, and ankles. The ouput structure of the {\em MMPose} model can be found in \in{Figure}[mmpose-skeleton].

The model is divided into {\em two} main stages. The first stage detects human bodies in the input image. This is done using a {\em Faster R-CNN} detector, which is a {\em two-stage} object detection network. The detector first extracts a set of {\em region proposals} from the image, and then {\em classifies} each proposal as either a {\em human} or {\em not} (\scc Ke et al., 2019).

The second stage estimates the poses of the detected human bodies. This is done using a {\em top-down} pose estimation network, which is a \CNN\ that takes as input the bounding boxes of the detected bodies and outputs a set of heatmaps that represent the probability of each keypoint being located at each pixel in the image (\scc Ke et al., 2019).

The top-down pose estimation network is based on the {\em HRNet} architecture, which is a deep \CNN\ that is designed for human pose estimation. The network consists of a series of {\em residual blocks}, each of which consists of two convolutional layers with a {\em stride} of 1 followed by two convolutional layers with a stride of 2. This allows the network to capture both local and global information in the image (\scc Ke et al., 2019).

The human pose estimation results are then evaluated using the COCO WholeBody metric (\scc Jin et al., 2020; \scc Xe et al., 2022), which is a measure of the accuracy of the predicted keypoints.

\TABULKA[][tab:mmpose-features]{MMPose model features}
    \setupTABLE[r][1][style=bold]
    \setupTABLE[c][each][offset=3dd]
    \setupTABLE[frame=off]
    \setupTABLE[r][1][topframe=on,bottomframe=on]
    \setupTABLE[c][each][leftframe=on]
    \setupTABLE[c][1][leftframe=off]
    \bTR
        \bTD Feature\eTD\bTD    Description\eTD\eTR
    \bTR
        \bTD Input\eTD\bTD	    RGB image or video frame\eTD\eTR
    \bTR
        \bTD Output\eTD\bTD	    List of pose landmarks for each person detected in the input\eTD\eTR
    \bTR
        \bTD Landmarks\eTD\bTD	133 keypoints\eTD\eTR
    \bTR
        \bTD Accuracy\eTD\bTD   76.3\% on the COCO WholeBody dataset\eTD\eTR
    \bTR
        \bTD Speed\eTD\bTD	    Requires a powerful GPU for real-time use\eTD\eTR

\obrazek{mmpose-skeleton}{MMPose skeleton structure with IDs of used keypoint in the further processing. For simplicity, the small blue points do not have ID ensuring good visibility. Additionally, the blue keypoints have been omitted to achieve the unified format described in \\in{section}[section:unified-format] on \\at{page}[section:unified-format]}{figures/mmpose-detection-structure.png}{width=36cc,height=41cc}

% % ------- Section ------- %
% \pkap[section:chapter-summary]{Chapter Summary}
% This chapter introduced the key concepts of \NN\-s, \CNN\-s, \RCNN\-s and existing models for human pose estimation. These concepts provide the theoretical foundation for the proposed automated \NN\ learning approach.

% Introduction to NN
% \RCNN\  Region-based Convolutional Neural Network vs CNN Convolutional Neural Network
% Investigation of existing NNs for skeleton detection
% NN transformation models
