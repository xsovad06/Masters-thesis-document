\kap[chapter:conclusion]{Discussion and Conclusion}

This chapter will discuss the work presented in this thesis and draw conclusions based on its findings. It will explore the methods used, what has been learned, and the implications for the field. The discussion will highlight both successes and challenges encountered during the research. Then, in the conclusion, the key findings will be summarised, and their implications for future research and practical applications will be discussed. This chapter provides a clear overview of the research journey and its significance.

% ------- Section ------- %
\pkap[section:discussion]{Discussion}
As we discuss this work, the aim is to provide a comprehensive overview of its achievements and challenges. The discussion begins by highlighting the successes that have bolstered its robustness, shedding light on the strategies and implementations that have proven effective. Subsequently, attention is given to areas with room for improvement, addressing technical limitations and implementation hurdles in a separate subsection. This discussion provides valuable insights into this project's journey, highlighting its strengths and areas ripe for further development.

The original goal of this work could not be implemented entirely due to unforeseen circumstances. The company for which this work was aimed decided not to proceed with supporting the original plan, detaching from the consultation role. It was a small start-up focusing on \HPE\ for healthcare use cases, such as detecting falling people in nursing homes. The original goal was to provide a new cost-efficient approach to train or retrain the detection model on their customers' data, specifically videos capturing people falling in nursing facilities. However, the company did not provide any production data for dataset generation, necessitating a change in the course of this work. Despite that, the unification process was successfully proposed, implemented, and evaluated, aligning with this work's original plan and goal.

To summarise, the only part missing from the original assessment is the training or retraining of a new model for production use. Another problem was that training or retraining a new complex model requires computational resources that the company should have provided. After their withdrawal, this part of the assessment was impossible to achieve.

This thesis is motivated by insights from \scl Alinezhad Noghre et al. (2022), which stress the importance of creating high-quality custom datasets due to the large amount of data needing analysis. To achieve this, powerful and robust models are essential. However, appropriate datasets are crucial for models to perform well in real-life situations. This thesis proposes a different method for generating datasets compared to \scl Alinezhad Noghre et al. (2022). While their approach involves three processing stages (to address all challenges aligned in \in{Section}[section:pose-estimation-challanges] on \at{page}[section:pose-estimation-challanges]) to create tailored datasets, it is more complex and challenging to implement than the method proposed in this thesis. Both approaches have advantages and limitations, so their value can be observed in various use cases.

The first notable achievement is implementing functional scripts and comprehensive documentation built from scratch. Preparing and fine-tuning scripts for running individual detection models was the most time-consuming aspect. Throughout development, these scripts' design and functionality underwent several revisions. Another noteworthy aspect is the versatility of the created tools. A rich selection of arguments for these scripts provides some flexibility in their utilisation, which may not necessarily be directly related to creating specialised datasets. The detection scripts offer the option to record videos via webcam and perform real-time pose detection with rendering. However, this functionality applies only to MoveNet and PoseNet, optimised for real-time detection.

Let us address areas where the performance could have been more satisfactory. It is worth mentioning that individual scripts lack comprehensive test coverage. This stemmed from time constraints during the implementation phase when functionality preceded best practices such as writing tests. Therefore, future work should include test implementation for the scripts to ensure functionality remains intact amid significant architectural changes. Further issues or areas of lesser success are elaborated on in the following subsection.

% ------- Subsection ------- %
\ppkap[subsection:problems-limitations]{Technical Limitations and Implementation Problems}
Throughout this thesis, there have been many technical limitations and im\-plementation struggles. This subsection will list some of them.

The initial plan was to utilise the \pojem{BodyPoseNet} (NVIDIA, 2024) detection model from \pojem{NVIDIA}, which supports multi-person detection and boasts high power and precision. However, after numerous unsuccessful attempts to implement the BodyPoseNet detection script, a decision was made to move forward with a different model to avoid further time constraints. The primary challenge was that BodyPoseNet necessitated an NVIDIA GPU unit in conjunction with the DeepStream toolkit. Unfortunately, the development environment for this thesis consisted of macOS \pojem{Sonoma} on a \pojem{16-inch MacBook Pro with M1 Max chip and 64GB of RAM}, which lacks an NVIDIA GPU. The initial attempts to implement BodyPoseNet detection involved a virtual machine running \pojem{Ubuntu 22.04} on \pojem{Parallels Desktop}. Subsequently, this same virtual machine environment was used for all other detection models explored. Once it was discovered that detection could be performed directly on the native MacBook environment, the virtual machine was no longer required.

\obrazkyvedlesebe[2*2][top]{compose-fig:mmpose-problem;compose-fig:posenet-problem;compose-fig:unified-problem;compose-fig:coco-problem}
 {
 MMPose;
 PoseNet;
 Unified Format;
 COCO Annotations;
 }
 {
 figures/instance-mapping-problem/000000065350-mmpose.jpg;
 figures/instance-mapping-problem/000000065350-posenet.jpg;
 figures/instance-mapping-problem/000000065350-unified.jpg;
 figures/instance-mapping-problem/000000065350-coco.jpg;
 }
 {
 height=10.5cc;
 height=10.5cc;
 height=10.5cc;
 height=10.5cc;
 }

There are also some implementation limitations regarding the creation of the Unified Format. A problem arises when averaging detections, primarily when some models do not provide \BBOX\ values. For instance, PoseNet and MoveNet do not generate \BBOX\ information, making it challenging to map the appropriate detection instances for averaging. This issue is particularly pronounced in examples from the COCO evaluation subset, as illustrated in Figures \in[compose-fig:mmpose-problem], \in[compose-fig:posenet-problem], and \in[compose-fig:unified-problem].

In Figure \in[compose-fig:posenet-problem], for instance, the mapping of the jumping person from the PoseNet model in the middle of the Figure is incorrectly associated with a different instance from the MMPose model, depicted as a person on the right. Consequently, averaging these two detections results in the placement of the detection in between in the Unified Format output. Although the unified version of the detection appears slightly distorted, it demonstrates how the averaging process combines the original detections. In this case, the MoveNet model did not provide any results, prompting the unification script to consider only MMPose and PoseNet detections.

These issues could be addressed by implementing a custom function that compares two instances from the detection scripts and returns a similarity constant. This constant would serve as a basis for determining if the two detection instances correspond. Utilising the \BBOX\ information provided by the MMPose model, for example, could facilitate comparison by defining an area of overlap for individual keypoints from the other two models if a certain percentage of keypoints fit into a \BBOX\ (for example, 65\%, similar to an \IoU\ threshold introduced in \in{Section}[section:evaluation]), the instances would be considered corresponding.

Another problem arose during the evaluation of detection performance. The \pojem{\OKS} metric utilises the object scale to normalise the value and mitigate the disproportionate influence of larger objects. Initially, the object scale is calculated as the product of {\it bbox_width} and {\it bbox_height} multiplication, which is then squared in the \OKS\ formula. However, this approach yielded excessively high values, resulting in nearly perfect \OKS\ values even for completely inaccurate poses. By eliminating the squaring process, the \OKS\ values returned to a normal range, accurately representing the pose similarity.

% ------- Section ------- %
\pkap[section:conclusion]{Conclusion}

The development of a \pojem{Unified Format} for \pojem{\HPE\ dataset creation} represents a significant advancement in \pojem{simplifying and standardising} the \pojem{aggregation of results} from diverse \NN\ models. By addressing the variations in output formats among existing models like MoveNet, PoseNet, and MMPose, the Unified Format harmonises these outputs into a cohesive structure. This achievement streamlines the dataset generation process, en\-abling the training of tailored models for specific detection tasks.

The evaluation of the Unified Format's performance revealed promising results, particularly in metrics like \pojem{\APE} ({\bf 3.3\%}) and \pojem{\MSE} ({\bf 1,213.84}), where low values indicate close alignment between predicted and ground truth keypoints. The \pojem{\OKS} metric ({\bf 0.23}), though helpful in measuring similarity, faced challenges because of strict evaluation standards and differences in predictions between models. Nonetheless, the Unified Format demonstrated \pojem{satisfactory performance} accurately \pojem{localising keypoints}, especially when compared to individual model outputs. The low value of the OKS metric can be attributed to the fact that the selection of detection models prioritised ease of use and speed over maximum accuracy. In real-world applications, where creating specific datasets is paramount, employing more accurate models focused on precision rather than real-time usage would undoubtedly yield higher OKS scores.

Despite the overall success of the Unified Format, several areas warrant further attention for refinement. Firstly, \pojem{enhancing} the \pojem{unification process} to better handle instances where individual models produce \pojem{divergent results} could improve overall accuracy. This could involve refining the weighting scheme for averaging predictions or implementing \pojem{adaptive strategies} to accommodate varying model outputs.

Additionally, investigating techniques to mitigate errors introduced during the unification process, such as erroneous pose predictions, could lead to more robust dataset generation. Strategies like \pojem{outlier detection} or \pojem{dynamic thresh\-olding} based on model confidence scores may help improve the quality of Unified Format outputs.

Furthermore, exploring \pojem{alternative evaluation metrics} or refining existing ones, mainly \pojem{\OKS}, to reflect the nuances of pose estimation accuracy better could enhance the assessment process. This may involve adjusting keypoint similarity criteria or incorporating contextual information to account for pose variations in real-world scenarios.

In summary, the practical part of the thesis has successfully addressed the challenges associated with \HPE\ dataset creation by proposing and implementing a \pojem{Unified Format}. This format facilitates the aggregation of outputs from multiple \NN\ models, streamlining the dataset generation process. Evaluation results indicate promising performance, with low \APE\ and \MSE\ values demonstrating close alignment between predicted and ground truth keypoints. While challenges remain, continued refinement and exploration of techniques offer opportunities to improve the Unified Format further and advance the field of \HPE\. The main aim of this thesis has been successfully accomplished, perfectly matching the objectives set out in its introduction. Every part of the thesis has been carefully carried out, leading to a thorough achievement of its intended goals.
